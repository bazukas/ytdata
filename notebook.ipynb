{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views/likes/dislikes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = pd.read_csv('data/USvideos.csv')\n",
    "gb_data = pd.read_csv('data/GBvideos.csv')\n",
    "ca_data = pd.read_csv('data/CAvideos.csv')\n",
    "\n",
    "df = pd.concat([us_data, gb_data, ca_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language filter\n",
    "\n",
    "Warning: slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(row):\n",
    "    t = '\\n'.join([str(row['title']), str(row['description'])])\n",
    "    try:\n",
    "        return langdetect.detect(t)\n",
    "    except:\n",
    "        return 'err'\n",
    "\n",
    "df['lang'] = df.apply(detect_lang, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description.fillna('', inplace=True)\n",
    "df.title.fillna('', inplace=True)\n",
    "df.tags.fillna('', inplace=True)\n",
    "df['alltext'] = df['title'] + ' ' + df['description'] + ' ' + df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['channel'] = df['channel_title'].astype('category')\n",
    "df['channel'] = df['channel'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / dev / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.sample(frac=1)\n",
    "X = dfs[['alltext', 'channel', 'category_id']]\n",
    "Y = dfs[['views', 'likes', 'dislikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "X_test, X_dev, Y_test, Y_dev = train_test_split(X_test, Y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65564, 3)\n",
      "(8196, 3)\n",
      "(8196, 3)\n",
      "(65564, 3)\n",
      "(8196, 3)\n",
      "(8196, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_dev.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def eval_metric(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def train_eval_model(model, features, target):\n",
    "    assert target in ['views', 'likes', 'dislikes']\n",
    "    model.fit(X_train[features].values, Y_train[target])\n",
    "    return (eval_metric(Y_train[target], model.predict(X_train[features].values)),\n",
    "            eval_metric(Y_dev[target], model.predict(X_dev[features].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(models, names, features):\n",
    "    best = {\n",
    "        'views': None,\n",
    "        'likes': None,\n",
    "        'dislikes': None,\n",
    "    }\n",
    "    for target in ['views', 'likes', 'dislikes']:\n",
    "        print(\"Selecting model for \", target)\n",
    "        for model, name in zip(sklearn.base.clone(models), names):\n",
    "            print(\"Training \", name)\n",
    "            train_err, dev_err = train_eval_model(model, features, target)\n",
    "            print(\"Train err: %f, Dev err: %f\" % (train_err, dev_err))\n",
    "            if best[target] is None or best[target]['dev'] > dev_err:\n",
    "                best[target] = {\n",
    "                    'model': model,\n",
    "                    'name': name,\n",
    "                    'dev': dev_err,\n",
    "                    'train': train_err,\n",
    "                }\n",
    "    print(\"Views model: %s, train: %f, dev: %f\" %\n",
    "              (best['views']['name'], best['views']['train'], best['views']['dev']))\n",
    "    print(\"Likes model: %s, train: %f, dev: %f\" %\n",
    "              (best['likes']['name'], best['likes']['train'], best['likes']['dev']))\n",
    "    print(\"Dislikes model: %s, train: %f, dev: %f\" %\n",
    "              (best['dislikes']['name'], best['dislikes']['train'], best['dislikes']['dev']))\n",
    "    return best['views']['model'], best['likes']['model'], best['dislikes']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, names = zip(*[\n",
    "    (RandomForestRegressor(n_estimators=10), \"Random Forest\"),\n",
    "    (RidgeCV(alphas=[0.0001, 0.001, 0.01, 0.1, 1.0, 10]), \"RidgeCV\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 5182425.779468, Dev err: 6093255.321696\n",
      "Training  RidgeCV\n",
      "Train err: 8528297.649530, Dev err: 9938056.005447\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 103136.809334, Dev err: 116303.196309\n",
      "Training  RidgeCV\n",
      "Train err: 198230.436906, Dev err: 225573.735759\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 20122.750107, Dev err: 21383.727413\n",
      "Training  RidgeCV\n",
      "Train err: 32807.857864, Dev err: 32753.659842\n",
      "Views model: Random Forest, train: 5182425.779468, dev: 6093255.321696\n",
      "Likes model: Random Forest, train: 103136.809334, dev: 116303.196309\n",
      "Dislikes model: Random Forest, train: 20122.750107, dev: 21383.727413\n"
     ]
    }
   ],
   "source": [
    "chan_views, chan_likes, chan_dislikes = select_model(models, names, ['channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 8317615.420495, Dev err: 9681581.376228\n",
      "Training  RidgeCV\n",
      "Train err: 8435252.012566, Dev err: 9830008.528452\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 190001.452207, Dev err: 216984.595891\n",
      "Training  RidgeCV\n",
      "Train err: 195494.390111, Dev err: 222549.713575\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 32603.418526, Dev err: 32776.852052\n",
      "Training  RidgeCV\n",
      "Train err: 32812.762948, Dev err: 32754.428125\n",
      "Views model: Random Forest, train: 8317615.420495, dev: 9681581.376228\n",
      "Likes model: Random Forest, train: 190001.452207, dev: 216984.595891\n",
      "Dislikes model: RidgeCV, train: 32812.762948, dev: 32754.428125\n"
     ]
    }
   ],
   "source": [
    "cat_views, cat_likes, cat_dislikes = select_model(models, names, ['category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel AND Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 5188674.173167, Dev err: 6034105.147710\n",
      "Training  RidgeCV\n",
      "Train err: 8435167.838002, Dev err: 9829832.913317\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 100706.788303, Dev err: 115303.665551\n",
      "Training  RidgeCV\n",
      "Train err: 195451.974301, Dev err: 222501.077833\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 19845.189330, Dev err: 21115.229526\n",
      "Training  RidgeCV\n",
      "Train err: 32803.104194, Dev err: 32740.237110\n",
      "Views model: Random Forest, train: 5188674.173167, dev: 6034105.147710\n",
      "Likes model: Random Forest, train: 100706.788303, dev: 115303.665551\n",
      "Dislikes model: Random Forest, train: 19845.189330, dev: 21115.229526\n"
     ]
    }
   ],
   "source": [
    "chancat_views, chancat_likes, chancat_dislikes = select_model(models, names, ['channel', 'category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=30000, stop_words='english')\n",
    "vectorizer.fit(X_train['alltext'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_train = vectorizer.transform(X_train['alltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_dev = vectorizer.transform(X_dev['alltext'])\n",
    "tfidf_X_test = vectorizer.transform(X_test['alltext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SGD regressor because number of features is very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-05, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_views_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0.00001)\n",
    "tfidf_views_model.fit(tfidf_X_train, Y_train['views'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views train err:  4661384.501312322\n",
      "Views dev err:  5359398.33774294\n"
     ]
    }
   ],
   "source": [
    "print(\"Views train err: \", eval_metric(Y_train['views'].values, tfidf_views_model.predict(tfidf_X_train)))\n",
    "print(\"Views dev err: \", eval_metric(Y_dev['views'].values, tfidf_views_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0)\n",
    "likes_model.fit(tfidf_X_train, Y_train['likes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes train err:  78805.76721026869\n",
      "Likes dev err:  90689.80721719166\n"
     ]
    }
   ],
   "source": [
    "print(\"Likes train err: \", eval_metric(Y_train['likes'].values, likes_model.predict(tfidf_X_train)))\n",
    "print(\"Likes dev err: \", eval_metric(Y_dev['likes'].values, likes_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dislikes_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0)\n",
    "dislikes_model.fit(tfidf_X_train, Y_train['dislikes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dislikes train err:  15534.158980529544\n",
      "Dislikes dev err:  13089.850712527501\n"
     ]
    }
   ],
   "source": [
    "print(\"Dislikes train err: \", eval_metric(Y_train['dislikes'].values, dislikes_model.predict(tfidf_X_train)))\n",
    "print(\"Dislikes dev err: \", eval_metric(Y_dev['dislikes'].values, dislikes_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PV-DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvdm import PVDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdm = PVDM('data/fasttext_en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 11.500093\n",
      "iter: 100, loss: 11.255790\n",
      "iter: 200, loss: 10.927731\n",
      "iter: 300, loss: 10.351659\n",
      "iter: 400, loss: 10.041838\n",
      "iter: 500, loss: 9.816584\n",
      "iter: 600, loss: 9.247374\n",
      "iter: 700, loss: 8.836740\n",
      "iter: 800, loss: 8.550824\n",
      "iter: 900, loss: 9.107790\n",
      "iter: 1000, loss: 8.945185\n",
      "iter: 1100, loss: 9.160015\n",
      "iter: 1200, loss: 8.884859\n",
      "iter: 1300, loss: 8.106627\n",
      "iter: 1400, loss: 8.402533\n",
      "iter: 1500, loss: 8.156935\n",
      "iter: 1600, loss: 8.956823\n",
      "iter: 1700, loss: 8.423058\n",
      "iter: 1800, loss: 8.266140\n",
      "iter: 1900, loss: 9.126919\n",
      "iter: 2000, loss: 9.154280\n",
      "iter: 2100, loss: 8.596383\n",
      "iter: 2200, loss: 8.777518\n",
      "iter: 2300, loss: 9.195590\n",
      "iter: 2400, loss: 8.264833\n",
      "iter: 2500, loss: 8.894335\n",
      "iter: 2600, loss: 8.197789\n",
      "iter: 2700, loss: 8.140443\n",
      "iter: 2800, loss: 8.227644\n",
      "iter: 2900, loss: 8.323967\n",
      "iter: 2999, loss: 7.700732\n"
     ]
    }
   ],
   "source": [
    "pvdm_X_train = pvdm.train(list(X_train['alltext'].values), max_iter=3000, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 8.226328\n",
      "iter: 100, loss: 8.449644\n",
      "iter: 200, loss: 7.915804\n",
      "iter: 300, loss: 7.915294\n",
      "iter: 400, loss: 7.762508\n",
      "iter: 500, loss: 8.304609\n",
      "iter: 600, loss: 8.304291\n",
      "iter: 700, loss: 8.211000\n",
      "iter: 800, loss: 8.316038\n",
      "iter: 900, loss: 8.293601\n",
      "iter: 999, loss: 7.377135\n"
     ]
    }
   ],
   "source": [
    "pvdm_X_dev = pvdm.vectorize(list(X_dev['alltext'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01]), cv=None,\n",
       "    fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
       "    store_cv_values=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvdm_views_model = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10])\n",
    "pvdm_views_model.fit(pvdm_X_train, Y_train['views'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views train err:  8506653.041300824\n",
      "Views dev err:  9966533.197021779\n"
     ]
    }
   ],
   "source": [
    "print(\"Views train err: \", eval_metric(Y_train['views'].values, pvdm_views_model.predict(pvdm_X_train)))\n",
    "print(\"Views dev err: \", eval_metric(Y_dev['views'].values, pvdm_views_model.predict(pvdm_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01]), cv=None,\n",
       "    fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
       "    store_cv_values=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvdm_likes_model = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10])\n",
    "pvdm_likes_model.fit(pvdm_X_train, Y_train['likes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes train err:  197785.03082993082\n",
      "Likes dev err:  225953.51705522492\n"
     ]
    }
   ],
   "source": [
    "print(\"Likes train err: \", eval_metric(Y_train['likes'].values, pvdm_likes_model.predict(pvdm_X_train)))\n",
    "print(\"Likes dev err: \", eval_metric(Y_dev['likes'].values, pvdm_likes_model.predict(pvdm_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01]), cv=None,\n",
       "    fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
       "    store_cv_values=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvdm_dislikes_model = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10])\n",
    "pvdm_dislikes_model.fit(pvdm_X_train, Y_train['dislikes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dislikes train err:  32739.557838638317\n",
      "Dislikes dev err:  32874.26176056329\n"
     ]
    }
   ],
   "source": [
    "print(\"Dislikes train err: \", eval_metric(Y_train['dislikes'].values, pvdm_dislikes_model.predict(pvdm_X_train)))\n",
    "print(\"Dislikes dev err: \", eval_metric(Y_dev['dislikes'].values, pvdm_dislikes_model.predict(pvdm_X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Views | Likes | Dislikes |\n",
    "| ---   |  ---  | ---   | ---      |\n",
    "| Channel | 6093255.321696 | 116303.196309 | 21383.727413 |\n",
    "| Category | 9681581.376228 | 216984.595891 | 32754.428125 |\n",
    "| Channel+Category | 6034105.147710 | 115303.665551 | 21115.229526 |\n",
    "| TF-IDF | 5359398.33774294 | 90689.80721719166 | 13089.850712527501 |\n",
    "| PV-DV | 9966533.197021779 | 225953.51705522492 | 32874.26176056329 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it's probably possible to achieve better results with PV-DM, I did not do proper hyperparamtere tuning and model selection because it takes too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views test err:  4954561.639136972\n",
      "Likes test err:  87758.77243487755\n",
      "Dislikes test err:  15821.163421204124\n"
     ]
    }
   ],
   "source": [
    "print(\"Views test err: \", eval_metric(Y_test['views'].values, tfidf_views_model.predict(tfidf_X_test)))\n",
    "print(\"Likes test err: \", eval_metric(Y_test['likes'].values, likes_model.predict(tfidf_X_test)))\n",
    "print(\"Dislikes test err: \", eval_metric(Y_test['dislikes'].values, dislikes_model.predict(tfidf_X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

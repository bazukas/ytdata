{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views/likes/dislikes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = pd.read_csv('data/USvideos.csv')\n",
    "gb_data = pd.read_csv('data/GBvideos.csv')\n",
    "ca_data = pd.read_csv('data/CAvideos.csv')\n",
    "\n",
    "df = pd.concat([us_data, gb_data, ca_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(row):\n",
    "    t = '\\n'.join([str(row['title']), str(row['description'])])\n",
    "    try:\n",
    "        return langdetect.detect(t)\n",
    "    except:\n",
    "        return 'err'\n",
    "\n",
    "df['lang'] = df.apply(detect_lang, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_to_trend'] = df['trending_date'] - df['publish_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description.fillna('', inplace=True)\n",
    "df.title.fillna('', inplace=True)\n",
    "df.tags.fillna('', inplace=True)\n",
    "df['alltext'] = df['title'] + ' ' + df['description'] + ' ' + df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['channel'] = df['channel_title'].astype('category')\n",
    "df['channel'] = df['channel'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / dev / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.sample(frac=1)\n",
    "X = dfs[['alltext', 'channel', 'category_id']]\n",
    "Y = dfs[['views', 'likes', 'dislikes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "X_test, X_dev, Y_test, Y_dev = train_test_split(X_test, Y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70261, 3)\n",
      "(8783, 3)\n",
      "(8783, 3)\n",
      "(70261, 3)\n",
      "(8783, 3)\n",
      "(8783, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_dev.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def eval_metric(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def train_eval_model(model, features, target):\n",
    "    assert target in ['views', 'likes', 'dislikes']\n",
    "    model.fit(X_train[features].values, Y_train[target])\n",
    "    return (eval_metric(Y_train[target], model.predict(X_train[features].values)),\n",
    "            eval_metric(Y_dev[target], model.predict(X_dev[features].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(models, names, features):\n",
    "    best = {\n",
    "        'views': None,\n",
    "        'likes': None,\n",
    "        'dislikes': None,\n",
    "    }\n",
    "    for target in ['views', 'likes', 'dislikes']:\n",
    "        print(\"Selecting model for \", target)\n",
    "        for model, name in zip(sklearn.base.clone(models), names):\n",
    "            print(\"Training \", name)\n",
    "            train_err, dev_err = train_eval_model(model, features, target)\n",
    "            print(\"Train err: %f, Dev err: %f\" % (train_err, dev_err))\n",
    "            if best[target] is None or best[target]['dev'] > dev_err:\n",
    "                best[target] = {\n",
    "                    'model': model,\n",
    "                    'name': name,\n",
    "                    'dev': dev_err,\n",
    "                    'train': train_err,\n",
    "                }\n",
    "    print(\"Views model: %s, train: %f, dev: %f\" %\n",
    "              (best['views']['name'], best['views']['train'], best['views']['dev']))\n",
    "    print(\"Likes model: %s, train: %f, dev: %f\" %\n",
    "              (best['likes']['name'], best['likes']['train'], best['likes']['dev']))\n",
    "    print(\"Dislikes model: %s, train: %f, dev: %f\" %\n",
    "              (best['dislikes']['name'], best['dislikes']['train'], best['dislikes']['dev']))\n",
    "    return best['views']['model'], best['likes']['model'], best['dislikes']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, names = zip(*[\n",
    "    (RandomForestRegressor(n_estimators=10), \"Random Forest\"),\n",
    "    (RidgeCV(), \"RidgeCV\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 6192499.765740, Dev err: 7098472.222174\n",
      "Training  RidgeCV\n",
      "Train err: 10127596.334401, Dev err: 13145960.821158\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 104566.583243, Dev err: 111207.601193\n",
      "Training  RidgeCV\n",
      "Train err: 204313.931787, Dev err: 211667.960349\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 27260.155075, Dev err: 20683.684098\n",
      "Training  RidgeCV\n",
      "Train err: 40140.474151, Dev err: 32477.209702\n",
      "Views model: Random Forest, train: 6192499.765740, dev: 7098472.222174\n",
      "Likes model: Random Forest, train: 104566.583243, dev: 111207.601193\n",
      "Dislikes model: Random Forest, train: 27260.155075, dev: 20683.684098\n"
     ]
    }
   ],
   "source": [
    "chan_views, chan_likes, chan_dislikes = select_model(models, names, ['channel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 9866500.230407, Dev err: 12853978.206174\n",
      "Training  RidgeCV\n",
      "Train err: 10018397.213103, Dev err: 13028218.963434\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 195484.798433, Dev err: 202117.482390\n",
      "Training  RidgeCV\n",
      "Train err: 201330.885721, Dev err: 208481.913170\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 39995.260741, Dev err: 32243.687084\n",
      "Training  RidgeCV\n",
      "Train err: 40140.194049, Dev err: 32473.375132\n",
      "Views model: Random Forest, train: 9866500.230407, dev: 12853978.206174\n",
      "Likes model: Random Forest, train: 195484.798433, dev: 202117.482390\n",
      "Dislikes model: Random Forest, train: 39995.260741, dev: 32243.687084\n"
     ]
    }
   ],
   "source": [
    "cat_views, cat_likes, cat_dislikes = select_model(models, names, ['category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel AND Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model for  views\n",
      "Training  Random Forest\n",
      "Train err: 6177665.852854, Dev err: 7171541.241929\n",
      "Training  RidgeCV\n",
      "Train err: 10018262.367244, Dev err: 13027258.791271\n",
      "Selecting model for  likes\n",
      "Training  Random Forest\n",
      "Train err: 102707.069348, Dev err: 108652.568836\n",
      "Training  RidgeCV\n",
      "Train err: 201309.266142, Dev err: 208442.972291\n",
      "Selecting model for  dislikes\n",
      "Training  Random Forest\n",
      "Train err: 27265.172905, Dev err: 20649.202800\n",
      "Training  RidgeCV\n",
      "Train err: 40135.166088, Dev err: 32465.433668\n",
      "Views model: Random Forest, train: 6177665.852854, dev: 7171541.241929\n",
      "Likes model: Random Forest, train: 102707.069348, dev: 108652.568836\n",
      "Dislikes model: Random Forest, train: 27265.172905, dev: 20649.202800\n"
     ]
    }
   ],
   "source": [
    "chancat_views, chancat_likes, chancat_dislikes = select_model(models, names, ['channel', 'category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=30000, stop_words='english')\n",
    "vectorizer.fit(df['alltext'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_train = vectorizer.transform(X_train['alltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_dev = vectorizer.transform(X_dev['alltext'])\n",
    "tfidf_X_test = vectorizer.transform(X_test['alltext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SGD regressor because number of features is very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-05, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_views_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0.00001)\n",
    "tfidf_views_model.fit(tfidf_X_train, Y_train['views'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views train err:  5495007.174184686\n",
      "Views dev err:  6606515.312405204\n"
     ]
    }
   ],
   "source": [
    "print(\"Views train err: \", eval_metric(Y_train['views'].values, tfidf_views_model.predict(tfidf_X_train)))\n",
    "print(\"Views dev err: \", eval_metric(Y_dev['views'].values, tfidf_views_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0)\n",
    "likes_model.fit(tfidf_X_train, Y_train['likes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes train err:  97584.03789649117\n",
      "Likes dev err:  103454.07268251332\n"
     ]
    }
   ],
   "source": [
    "print(\"Likes train err: \", eval_metric(Y_train['likes'].values, likes_model.predict(tfidf_X_train)))\n",
    "print(\"Likes dev err: \", eval_metric(Y_dev['likes'].values, likes_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azat/.pyenv/versions/3.6.7/envs/youtubeml/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1192: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=2000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dislikes_model = SGDRegressor(max_iter=2000, tol=1e-3, alpha=0)\n",
    "dislikes_model.fit(tfidf_X_train, Y_train['dislikes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dislikes train err:  19957.785186487672\n",
      "Dislikes dev err:  14388.956251537587\n"
     ]
    }
   ],
   "source": [
    "print(\"Dislikes train err: \", eval_metric(Y_train['dislikes'].values, dislikes_model.predict(tfidf_X_train)))\n",
    "print(\"Dislikes dev err: \", eval_metric(Y_dev['dislikes'].values, dislikes_model.predict(tfidf_X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
